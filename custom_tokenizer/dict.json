{
  "<START>": 0,
  "<END>": 1,
  "<UNK>": 2,
  "hello": 3,
  "howdy": 4,
  "how": 5,
  "are": 6,
  "you": 7,
  "my": 8,
  "names": 9,
  "is": 10,
  "mohsina": 11,
  "i": 12,
  "made": 13,
  "this": 14,
  "custom": 15,
  "tokenizer": 16,
  "it": 17,
  "will": 18,
  "learn": 19,
  "from": 20,
  "text": 21,
  "and": 22,
  "can": 23,
  "encode": 24,
  "decode": 25,
  "a": 26,
  "an": 27,
  "essential": 28,
  "part": 29,
  "of": 30,
  "processing": 31,
  "for": 32,
  "natural": 33,
  "language": 34,
  "nlp": 35,
  "tasks": 36,
  "takes": 37,
  "raw": 38,
  "input": 39,
  "splits": 40,
  "into": 41,
  "smaller": 42,
  "parts": 43,
  "called": 44,
  "tokens": 45,
  "which": 46,
  "be": 47,
  "words": 48,
  "characters": 49,
  "or": 50,
  "subwords": 51,
  "depending": 52,
  "on": 53,
  "the": 54,
  "designed": 55,
  "step": 56,
  "helps": 57,
  "convert": 58,
  "humanreadable": 59,
  "structured": 60,
  "format": 61,
  "that": 62,
  "handled": 63,
  "by": 64,
  "machine": 65,
  "learning": 66,
  "models": 67,
  "tokenization": 68,
  "often": 69,
  "includes": 70,
  "preprocessing": 71,
  "steps": 72,
  "such": 73,
  "as": 74,
  "converting": 75,
  "to": 76,
  "lowercase": 77,
  "removing": 78,
  "punctuation": 79,
  "handling": 80,
  "special": 81,
  "many": 82,
  "tokenizers": 83,
  "also": 84,
  "add": 85,
  "like": 86,
  "start": 87,
  "end": 88,
  "unk": 89,
  "mark": 90,
  "beginning": 91,
  "sequences": 92,
  "unknown": 93,
  "advanced": 94,
  "methods": 95,
  "byte": 96,
  "pair": 97,
  "encoding": 98,
  "bpe": 99,
  "wordpiece": 100,
  "break": 101,
  "uncommon": 102,
  "subword": 103,
  "units": 104,
  "so": 105,
  "still": 106,
  "understand": 107,
  "them": 108,
  "building": 109,
  "allows": 110,
  "control": 111,
  "over": 112,
  "vocabulary": 113,
  "size": 114,
  "token": 115,
  "mapping": 116,
  "rare": 117,
  "improve": 118,
  "both": 119,
  "accuracy": 120,
  "efficiency": 121,
  "": 122
}